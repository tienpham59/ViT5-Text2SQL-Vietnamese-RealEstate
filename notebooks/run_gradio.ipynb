{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27502,"status":"ok","timestamp":1746691277907,"user":{"displayName":"Ho√†ng Ti·∫øn Ph·∫°m","userId":"02745526515710768511"},"user_tz":-420},"id":"BWLaL9pclVH7","outputId":"d7091e9e-a08c-4412-d5cb-61653973624c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# ====== SETUP + INSTALL ======\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1692,"status":"ok","timestamp":1746691279590,"user":{"displayName":"Ho√†ng Ti·∫øn Ph·∫°m","userId":"02745526515710768511"},"user_tz":-420},"id":"n_Ew9C38lXXa","outputId":"535b9e55-543d-4c54-f360-d7cac636e2c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/DuÃõÃ£ aÃÅn - baÃÅo caÃÅo/Do_an_HK3_DT2210L_Text_To_SQL/vi_t5_text2sql\n"]}],"source":["%cd /content/drive/MyDrive/DuÃõÃ£ aÃÅn - baÃÅo caÃÅo/Do_an_HK3_DT2210L_Text_To_SQL/vi_t5_text2sql"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31039,"status":"ok","timestamp":1746691310626,"user":{"displayName":"Ho√†ng Ti·∫øn Ph·∫°m","userId":"02745526515710768511"},"user_tz":-420},"id":"YqCkWNVf6vJm","outputId":"cd2d2768-5724-4344-87ce-2f66187ad183"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (0.9.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n","Collecting gradio\n","  Downloading gradio-5.29.0-py3-none-any.whl.metadata (16 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Collecting aiofiles<25.0,>=22.0 (from gradio)\n","  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n","Collecting fastapi<1.0,>=0.115.2 (from gradio)\n","  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n","Collecting ffmpy (from gradio)\n","  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n","Collecting gradio-client==1.10.0 (from gradio)\n","  Downloading gradio_client-1.10.0-py3-none-any.whl.metadata (7.1 kB)\n","Collecting groovy~=0.1 (from gradio)\n","  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n","Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n","Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n","Collecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting python-multipart>=0.0.18 (from gradio)\n","  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n","Collecting ruff>=0.9.3 (from gradio)\n","  Downloading ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n","  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting starlette<1.0,>=0.40.0 (from gradio)\n","  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n","Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n","  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n","Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n","Downloading gradio-5.29.0-py3-none-any.whl (54.1 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.10.0-py3-none-any.whl (322 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m322.9/322.9 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n","Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n","Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n","Downloading ruff-0.11.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m130.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n","Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n","Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n","Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n","Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.29.0 gradio-client-1.10.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.8 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n","Collecting Unidecode\n","  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n","Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: Unidecode\n","Successfully installed Unidecode-1.4.0\n"]}],"source":["# ======== Import Libraries ========\n","!pip install tabulate transformers gradio\n","!pip install Unidecode\n","import gradio as gr\n","import re\n","import json\n","import pandas as pd\n","import sqlite3\n","import torch\n","from transformers import T5Tokenizer, T5ForConditionalGeneration\n","from tabulate import tabulate\n","from unidecode import unidecode\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Akr8mRc7lIjk","executionInfo":{"status":"ok","timestamp":1746691342800,"user_tz":-420,"elapsed":32166,"user":{"displayName":"Ho√†ng Ti·∫øn Ph·∫°m","userId":"02745526515710768511"}}},"outputs":[],"source":["# ======= CONFIG ========\n","model_dir = \"model/Final_model\"\n","db_path = \"data/processing/SQLite_real_estate.db\"\n","schema = \"address[str], area[float], frontage[float], access_road[float], house_direction[str], balcony_direction[str], \\\n","          floors[int], bedrooms[int], bathrooms[int], legal_status[str], furniture_state[str], price[float], city[str], district[str], \\\n","          ward[str], cluster_label[str]\"\n","\n","# Load nested JSON\n","with open(\"data/processing/locations.json\", \"r\", encoding=\"utf-8\") as f:\n","    nested = json.load(f)\n","\n","# Flatten: t·ª´ {city: {district: [ward, ...]}} ‚Üí list of dict\n","flat = []\n","for city, districts in nested.items():\n","    for district, wards in districts.items():\n","        for ward in wards:\n","            flat.append({\n","                \"city\": city,\n","                \"district\": district,\n","                \"ward\": ward\n","            })\n","\n","# Save file JSON\n","with open(\"data/processing/locations_flat.json\", \"w\", encoding=\"utf-8\") as f:\n","    json.dump(flat, f, ensure_ascii=False, indent=2)\n","\n","# Optionally: convert to CSV ƒë·ªÉ d·ªÖ nh√¨n\n","pd.DataFrame(flat).to_csv(\"data/processing/locations_flat.csv\", index=False)\n","filepath_location = \"data/processing/locations_flat.json\"\n","\n","# ======= LOAD MODEL ========\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","tokenizer = T5Tokenizer.from_pretrained(model_dir)\n","model = T5ForConditionalGeneration.from_pretrained(model_dir)\n","model.eval().to(device)\n","\n","# ======= STEP 1: X·ª≠ l√Ω c√¢u h·ªèi ƒë·∫ßu v√†o ========\n","full_schema = [tuple(col.strip().split(\"[\")) for col in schema.split(\",\")]\n","full_schema = [(col, dtype.strip(\"]\")) for col, dtype in full_schema]\n","\n","SCHEMA_KEYWORDS = {\n","    'address': ['ƒë·ªãa ch·ªâ'], 'area': ['di·ªán t√≠ch', 'm2', 'm√©t vu√¥ng'],\n","    'price': ['gi√°', 't·ª∑', 'tri·ªáu', 'bao nhi√™u ti·ªÅn'],\n","    'frontage': ['m·∫∑t ti·ªÅn'], 'access_road': ['ƒë∆∞·ªùng v√†o', 'ƒë∆∞·ªùng', 'h·∫ªm'],\n","    'house_direction': ['h∆∞·ªõng nh√†'], 'balcony_direction': ['h∆∞·ªõng ban c√¥ng'],\n","    'floors': ['t·∫ßng', 'l·∫ßu'], 'bedrooms': ['ph√≤ng ng·ªß'], 'bathrooms': ['ph√≤ng t·∫Øm', 'wc'],\n","    'legal_status': ['ph√°p l√Ω', 's·ªï h·ªìng', 's·ªï ƒë·ªè'], 'furniture_state': ['n·ªôi th·∫•t'],\n","    'city': ['th√†nh ph·ªë'], 'district': ['qu·∫≠n', 'huy·ªán'], 'ward': ['ph∆∞·ªùng', 'x√£'],\n","    'cluster_label': ['ph√¢n kh√∫c']\n","}\n","\n","def extract_relevant_columns_from_question(question: str, schema: list) -> list:\n","    question = question.lower()\n","    relevant = []\n","    for col, dtype in schema:\n","        if col in SCHEMA_KEYWORDS:\n","            for kw in SCHEMA_KEYWORDS[col]:\n","                if kw in question:\n","                    relevant.append((col, dtype))\n","                    break\n","    if 'gi√°' in question and ('price', 'float') not in relevant:\n","        relevant.append(('price', 'float'))\n","    return relevant\n","\n","def generate_input_text(question: str, schema_columns: list) -> str:\n","    schema_str = \", \".join([f\"{col}[{dtype}]\" for col, dtype in schema_columns])\n","    return f\"C√¢u h·ªèi: {question} | Schema: {schema_str}\"\n","\n","def normalize_question(text: str) -> str:\n","    \"\"\"\n","    Normalize a natural language question:\n","    - Convert to lowercase and strip whitespace\n","    - Convert expressions like \"2.5 t·ª∑\", \"3 tri·ªáu\" to numeric VND values\n","    - Normalize city name variants (e.g., SG, HCM ‚Üí h·ªì ch√≠ minh)\n","    \"\"\"\n","    try:\n","        text = text.lower().strip()\n","\n","        # Bi·∫øn th·ªÉ c·ªßa th√†nh ph·ªë H·ªì Ch√≠ Minh\n","        hcm_aliases = [\n","            \"th√†nh ph·ªë h·ªì ch√≠ minh\", \"tp h·ªì ch√≠ minh\", \"tp. h·ªì ch√≠ minh\", \"tphcm\",\n","            \"tp hcm\", \"tp.hcm\", \"hcm\", \"hcm city\",\n","            \"s√†i g√≤n\", \"tp sg\", \"th√†nh ph·ªë sg\", \"sg\", \"saigon\"\n","        ]\n","\n","        # Thay c√°c alias trong c√¢u h·ªèi th√†nh 'h·ªì ch√≠ minh'\n","        for alias in hcm_aliases:\n","            if alias in text:\n","                text = text.replace(alias, \"h·ªì ch√≠ minh\")\n","\n","        return text\n","    except Exception as e:\n","        print(f\"Error in normalize_question: {e}\")\n","        return text\n","\n","def load_locations(filepath: str):\n","    try:\n","        df = pd.read_csv(filepath) if filepath.endswith(\".csv\") else pd.read_json(filepath)\n","        return df[['city', 'district', 'ward']].dropna().drop_duplicates().to_dict(orient=\"records\")\n","    except Exception as e:\n","        print(f\"Error loading locations: {e}\")\n","        return []\n","\n","locations = load_locations(filepath_location)\n","def extract_location_from_question_v2(question: str, locations: list) -> dict:\n","    try:\n","        question = unidecode(question.lower())\n","        matched = {'city': None, 'district': None, 'ward': None}\n","\n","        # ∆Øu ti√™n match ward + ƒë√∫ng district n·∫øu district c√≥ xu·∫•t hi·ªán trong c√¢u h·ªèi\n","        for loc in locations:\n","            ward = unidecode(loc['ward'].lower())\n","            district = unidecode(loc['district'].lower())\n","            if re.search(rf'\\b{re.escape(ward)}\\b', question):\n","                if re.search(rf'\\b{re.escape(district)}\\b', question):\n","                    return {'city': loc['city'], 'district': loc['district'], 'ward': loc['ward']}\n","\n","        # N·∫øu kh√¥ng ƒë·ªß ward+district, th√¨ match district\n","        for loc in locations:\n","            district = unidecode(loc['district'].lower())\n","            if re.search(rf'\\b{re.escape(district)}\\b', question):\n","                matched['district'] = loc['district']\n","                matched['city'] = loc['city']\n","\n","        # Cu·ªëi c√πng, ch·ªâ match city n·∫øu kh√¥ng c√≥ g√¨ kh√°c\n","        for loc in locations:\n","            city = unidecode(loc['city'].lower())\n","            if not matched['district'] and re.search(rf'\\b{re.escape(city)}\\b', question):\n","                matched['city'] = loc['city']\n","\n","        return matched\n","    except Exception as e:\n","        print(f\"[extract_location_from_question_v2] Error: {e}\")\n","        return {'city': None, 'district': None, 'ward': None}\n","\n","\n","\n","# ======= STEP 2: Sinh SQL t·ª´ model ========\n","def inference_sql_from_question(raw_question: str) -> str:\n","    \"\"\"Sinh SQL t·ª´ c√¢u h·ªèi t·ª± nhi√™n b·∫±ng c√°ch tr√≠ch schema li√™n quan v√† g·ªçi model.\"\"\"\n","    try:\n","        question = normalize_question(raw_question)\n","        matched_location = extract_location_from_question_v2(question, locations)\n","        relevant_cols = extract_relevant_columns_from_question(question, full_schema)\n","        input_text = generate_input_text(question, relevant_cols)\n","\n","        inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True).to(device)\n","        outputs = model.generate(\n","            inputs.input_ids,\n","            max_length=64,\n","            num_beams=1,\n","            #config.early_stopping = False,\n","            decoder_start_token_id=model.config.decoder_start_token_id,\n","            pad_token_id=tokenizer.pad_token_id\n","        )\n","        return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","        raw_sql = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        sql = smart_fix_sql(raw_sql, question)\n","        sql = fix_location_in_sql(sql, matched_location)\n","        return sql\n","    except Exception as e:\n","        print(f\"Error during inference: {e}\")\n","        return \"\"\n","\n","\n","# ======= STEP 3: Fix SQL sau khi sinh ========\n","def smart_fix_sql(sql: str, question: str = \"\") -> str:\n","    \"\"\"\n","    Apply heuristic fixes to SQL:\n","    - Fix missing ANDs\n","    - Collapse repeated words\n","    - Convert BETWEEN if \"t·ª´ ... ƒë·∫øn\" is detected\n","    - Fix wrong comparison operators for phrases like 'd∆∞·ªõi', 'cao h∆°n', etc.\n","    \"\"\"\n","    try:\n","        sql = re.sub(r\"(\\d[\\)']?)\\s+([a-zA-Z_]+\\s*=)\", r\"\\1 AND \\2\", sql)\n","        sql = re.sub(r\"(\\d[\\)']?)\\s+([a-zA-Z_]+\\s*[><])\", r\"\\1 AND \\2\", sql)\n","        sql = re.sub(r\"\\b(\\w+)\\b(?:\\s+\\1\\b)+\", r\"\\1\", sql)\n","        if \"t·ª´\" in question and \"ƒë·∫øn\" in question:\n","          m = re.search(r\"price\\s*>=\\s*(\\d+\\.?\\d*)\\s*AND\\s*price\\s*<=\\s*(\\d+\\.?\\d*)\", sql)\n","          if m:\n","              x, y = m.groups()\n","              sql = re.sub(\n","                  r\"price\\s*>=\\s*\\d+\\.?\\d*\\s*AND\\s*price\\s*<=\\s*\\d+\\.?\\d*\",\n","                  f\"price BETWEEN {x} AND {y}\",\n","                  sql\n","              )\n","        if any(k in question for k in ['d∆∞·ªõi', '√≠t h∆°n', 'r·∫ª h∆°n', 'th·∫•p h∆°n']):\n","            sql = re.sub(r\"(price|quantity)\\s*>=\\s*(\\d+)\", r\"\\1 < \\2\", sql)\n","        if any(k in question for k in ['tr√™n', 'nhi·ªÅu h∆°n', 'cao h∆°n', 'ƒë·∫Øt h∆°n']):\n","            sql = re.sub(r\"(price|quantity)\\s*<=\\s*(\\d+)\", r\"\\1 > \\2\", sql)\n","        return sql\n","    except Exception as e:\n","        print(f\"Error in smart_fix_sql: {e}\")\n","        return sql\n","\n","def fix_location_in_sql(sql: str, matched_location: dict) -> str:\n","    try:\n","        sql = re.sub(r\"(AND\\s+)?(city|district|ward)\\s*=\\s*'[^']*'\", \"\", sql, flags=re.IGNORECASE)\n","        sql = re.sub(r\"\\s+WHERE\\s+AND\", \" WHERE \", sql, flags=re.IGNORECASE)\n","        sql = re.sub(r\"\\s+AND\\s+AND\", \" AND \", sql)\n","\n","        conditions = []\n","        if matched_location.get('ward'):\n","            conditions.append(f\"ward = '{matched_location['ward']}'\")\n","        if matched_location.get('district'):\n","            conditions.append(f\"district = '{matched_location['district']}'\")\n","        if matched_location.get('city'):\n","            conditions.append(f\"city = '{matched_location['city']}'\")\n","\n","        if not conditions:\n","            return sql.strip()\n","\n","        # T√¨m v·ªã tr√≠ ƒë·ªÉ ch√®n WHERE tr∆∞·ªõc ORDER BY / GROUP BY / LIMIT\n","        split_pattern = r\"\\b(order by|group by|limit|having)\\b\"\n","        parts = re.split(split_pattern, sql, flags=re.IGNORECASE)\n","\n","        if \"where\" in sql.lower():\n","            parts[0] += \" AND \" + \" AND \".join(conditions)\n","        else:\n","            parts[0] += \" WHERE \" + \" AND \".join(conditions)\n","\n","        return \" \".join(parts).strip()\n","    except Exception as e:\n","        print(f\"[fix_location_in_sql] Error: {e}\")\n","        return sql\n","\n","# ======= STEP 4: Th·ª±c hi·ªán truy v·∫•n SQLite ========\n","\n","def run_query(sql):\n","    try:\n","        conn = sqlite3.connect(db_path)\n","        cursor = conn.execute(sql)\n","        cols = [desc[0] for desc in cursor.description]\n","        rows = cursor.fetchall()\n","        conn.close()\n","        df = pd.DataFrame(rows, columns=cols)\n","\n","        # N·∫øu qu√° nhi·ªÅu d√≤ng th√¨ gi·ªõi h·∫°n preview\n","        return df.head(200) if len(df) > 200 else df\n","    except Exception as e:\n","        print(f\"Error running SQL query: {e}\")\n","        return pd.DataFrame(columns=[\"L·ªói\"], data=[[str(e)]])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"4Jh0IogjCvA1","outputId":"a484d670-11a5-4285-a48a-e6fa21401b68"},"outputs":[{"output_type":"stream","name":"stdout","text":["It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","* Running on public URL: https://96722cc56bff158966.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://96722cc56bff158966.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]},{"output_type":"stream","name":"stdout","text":["** B∆∞·ªõc 1: Chu·∫©n ho√° c√¢u h·ªèi...\n","C√¢u h·ªèi sau chu·∫©n ho√°: t√¨m nh√† ·ªü ph√∫ nhu·∫≠n gi√° d∆∞·ªõi 3 t·ª∑\n","- B∆∞·ªõc 2: Tr√≠ch xu·∫•t ƒë·ªãa danh...\n","ƒê·ªãa danh: {'city': 'H·ªì Ch√≠ Minh', 'district': 'Ph√∫ Nhu·∫≠n', 'ward': None}\n","‚Üí Input cho m√¥ h√¨nh: C√¢u h·ªèi: t√¨m nh√† ·ªü ph√∫ nhu·∫≠n gi√° d∆∞·ªõi 3 t·ª∑ | Schema: price[float]\n","- B∆∞·ªõc 3: Sinh SQL t·ª´ m√¥ h√¨nh...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:679: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["SQL raw: SELECT * FROM price_house WHERE price < 3000000000\n","- B∆∞·ªõc 4: Fix logic SQL...\n","SQL logic fixed: SELECT * FROM price_house WHERE price < 3000000000\n","- B∆∞·ªõc 5: Fix l·∫°i ƒë·ªãa danh trong SQL...\n","SQL final: SELECT * FROM price_house WHERE price < 3000000000 AND district = 'Ph√∫ Nhu·∫≠n' AND city = 'H·ªì Ch√≠ Minh'\n","- B∆∞·ªõc 6: Th·ª±c hi·ªán truy v·∫•n v√† tr·∫£ k·∫øt qu·∫£...\n","** B∆∞·ªõc 1: Chu·∫©n ho√° c√¢u h·ªèi...\n","C√¢u h·ªèi sau chu·∫©n ho√°: t√¨m nh√† ·ªü ph√∫ nhu·∫≠n gi√° d∆∞·ªõi 3 t·ª∑, di·ªán t√≠ch tr√™n 30m2\n","- B∆∞·ªõc 2: Tr√≠ch xu·∫•t ƒë·ªãa danh...\n","ƒê·ªãa danh: {'city': 'H·ªì Ch√≠ Minh', 'district': 'Ph√∫ Nhu·∫≠n', 'ward': None}\n","‚Üí Input cho m√¥ h√¨nh: C√¢u h·ªèi: t√¨m nh√† ·ªü ph√∫ nhu·∫≠n gi√° d∆∞·ªõi 3 t·ª∑, di·ªán t√≠ch tr√™n 30m2 | Schema: area[float], price[float]\n","- B∆∞·ªõc 3: Sinh SQL t·ª´ m√¥ h√¨nh...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:679: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["SQL raw: SELECT * FROM price_house WHERE price < 3000000000\n","- B∆∞·ªõc 4: Fix logic SQL...\n","SQL logic fixed: SELECT * FROM price_house WHERE price < 3000000000\n","- B∆∞·ªõc 5: Fix l·∫°i ƒë·ªãa danh trong SQL...\n","SQL final: SELECT * FROM price_house WHERE price < 3000000000 AND district = 'Ph√∫ Nhu·∫≠n' AND city = 'H·ªì Ch√≠ Minh'\n","- B∆∞·ªõc 6: Th·ª±c hi·ªán truy v·∫•n v√† tr·∫£ k·∫øt qu·∫£...\n","** B∆∞·ªõc 1: Chu·∫©n ho√° c√¢u h·ªèi...\n","C√¢u h·ªèi sau chu·∫©n ho√°: t√¨m nh√† ·ªü h√† n·ªôi gi√° d∆∞·ªõi 2 t·ª∑ di·ªán t√≠ch tr√™n 20m2\n","- B∆∞·ªõc 2: Tr√≠ch xu·∫•t ƒë·ªãa danh...\n","ƒê·ªãa danh: {'city': 'H√† N·ªôi', 'district': None, 'ward': None}\n","‚Üí Input cho m√¥ h√¨nh: C√¢u h·ªèi: t√¨m nh√† ·ªü h√† n·ªôi gi√° d∆∞·ªõi 2 t·ª∑ di·ªán t√≠ch tr√™n 20m2 | Schema: area[float], price[float]\n","- B∆∞·ªõc 3: Sinh SQL t·ª´ m√¥ h√¨nh...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:679: UserWarning: `num_beams` is set to 1. However, `early_stopping` is set to `True` -- this flag is only used in beam-based generation modes. You should set `num_beams>1` or unset `early_stopping`.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["SQL raw: SELECT * FROM price_house WHERE price < 2000000000 AND area > 20 AND city = 'H√† N·ªôi'\n","- B∆∞·ªõc 4: Fix logic SQL...\n","SQL logic fixed: SELECT * FROM price_house WHERE price < 2000000000 AND area > 20 AND city = 'H√† N·ªôi'\n","- B∆∞·ªõc 5: Fix l·∫°i ƒë·ªãa danh trong SQL...\n","SQL final: SELECT * FROM price_house WHERE price < 2000000000 AND area > 20  AND city = 'H√† N·ªôi'\n","- B∆∞·ªõc 6: Th·ª±c hi·ªán truy v·∫•n v√† tr·∫£ k·∫øt qu·∫£...\n"]}],"source":["# ====== GRADIO UI (Blocks layout) ======\n","with gr.Blocks(theme='soft') as demo:\n","    gr.Markdown(\"# üè° Text-to-SQL Real Estate Chatbot\")\n","    gr.Markdown(\"Nh·∫≠p c√¢u h·ªèi t·ª± nhi√™n, h·ªá th·ªëng s·∫Ω tr·∫£ k·∫øt qu·∫£ t·ª´ CSDL b·∫•t ƒë·ªông s·∫£n.\")\n","\n","    input_box = gr.Textbox(\n","        label=\"C√¢u h·ªèi c·ªßa b·∫°n\",\n","        placeholder=\"V√≠ d·ª•: T√¨m nh√† d∆∞·ªõi 3 t·ª∑ ·ªü G√≤ V·∫•p\",\n","        lines=2\n","    )\n","\n","    submit_btn = gr.Button(\"üì§ Submit\")\n","\n","    result_table = gr.Dataframe(label=\"K·∫øt qu·∫£ truy v·∫•n\", interactive=False)\n","\n","    # H√†m x·ª≠ l√Ω khi nh·∫•n Submit (ƒë·∫∑t b√™n trong block)\n","    def handle_query(user_input):\n","        print(\"** B∆∞·ªõc 1: Chu·∫©n ho√° c√¢u h·ªèi...\")\n","        normalized_q = normalize_question(user_input)\n","        print(\"C√¢u h·ªèi sau chu·∫©n ho√°:\", normalized_q)\n","\n","        print(\"- B∆∞·ªõc 2: Tr√≠ch xu·∫•t ƒë·ªãa danh...\")\n","        matched_location = extract_location_from_question_v2(normalized_q, locations)\n","        print(\"ƒê·ªãa danh:\", matched_location)\n","\n","        # Ch√®n th√™m print input t·∫°i ƒë√¢y n·∫øu mu·ªën\n","        relevant_cols = extract_relevant_columns_from_question(normalized_q, full_schema)\n","        input_text = generate_input_text(normalized_q, relevant_cols)\n","        print(\"‚Üí Input cho m√¥ h√¨nh:\", input_text)\n","\n","        print(\"- B∆∞·ªõc 3: Sinh SQL t·ª´ m√¥ h√¨nh...\")\n","        raw_sql = inference_sql_from_question(user_input)\n","        print(\"SQL raw:\", raw_sql)\n","\n","        print(\"- B∆∞·ªõc 4: Fix logic SQL...\")\n","        sql_fixed = smart_fix_sql(raw_sql, normalized_q)\n","        print(\"SQL logic fixed:\", sql_fixed)\n","\n","        print(\"- B∆∞·ªõc 5: Fix l·∫°i ƒë·ªãa danh trong SQL...\")\n","        final_sql = fix_location_in_sql(sql_fixed, matched_location)\n","        print(\"SQL final:\", final_sql)\n","\n","        print(\"- B∆∞·ªõc 6: Th·ª±c hi·ªán truy v·∫•n v√† tr·∫£ k·∫øt qu·∫£...\")\n","        return run_query(final_sql)\n","\n","    submit_btn.click(fn=handle_query, inputs=input_box, outputs=result_table)\n","\n","demo.launch(debug=True)\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1LicOfY6SahzReh5msVTsQ2EjHMbhfgWO","timestamp":1745656832330}],"gpuType":"T4","authorship_tag":"ABX9TyONEkUqhnSEb4AVCoHxTrPb"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}